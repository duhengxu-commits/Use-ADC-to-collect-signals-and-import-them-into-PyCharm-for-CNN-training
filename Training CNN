import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import (accuracy_score, precision_score,
                             recall_score, f1_score,
                             confusion_matrix, classification_report)
import seaborn as sns
import matplotlib.pyplot as plt
import joblib
import os
import time
from datetime import datetime
import warnings

# 忽略不必要的警告
warnings.filterwarnings("ignore")

# 设置随机种子确保可复现性
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)

# 设备配置
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"使用计算设备: {device}")


# ------------------ 数据预处理函数 ------------------
def apply_fft(features):
    """对输入特征应用FFT变换，保留有效频率成分"""
    fft_results = np.abs(np.fft.fft(features))
    num_features = features.shape[1]
    valid_fft = fft_results[:, :num_features // 2 + 1]  # 利用FFT对称性
    return valid_fft


def sliding_window_transform(signal, window_size=70, overlap=0.8):
    """将长序列信号转换为多个滑动窗口样本"""
    stride = int(window_size * (1 - overlap))
    # 确保步长至少为1
    stride = max(1, stride)
    windows = []
    # 计算可以提取的窗口数量
    num_windows = (len(signal) - window_size) // stride + 1

    for i in range(num_windows):
        start = i * stride
        end = start + window_size
        windows.append(signal[start:end])

    return np.array(windows)


# ------------------ 1D CNN模型定义（自适应特征维度） ------------------
class FFT_CNN1D(nn.Module):
    def __init__(self, input_dim, num_classes, dropout_rate=0.5):
        super(FFT_CNN1D, self).__init__()

        # 根据输入维度调整模型结构
        if input_dim <= 2:
            # 特征维度极小时使用简化模型
            self.features = nn.Sequential(
                nn.Conv1d(in_channels=1, out_channels=16, kernel_size=1, padding=0),
                nn.BatchNorm1d(16),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool1d(4)  # 直接自适应池化到固定大小
            )
            self.classifier = nn.Sequential(
                nn.Linear(16 * 4, 64),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(64, num_classes)
            )
        elif input_dim <= 10:
            # 特征维度较小时使用精简模型
            self.features = nn.Sequential(
                nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1),
                nn.BatchNorm1d(16),
                nn.ReLU(inplace=True),
                nn.MaxPool1d(kernel_size=2, stride=1),  # 减小步长避免尺寸为0
                nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1),
                nn.BatchNorm1d(32),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool1d(8)
            )
            self.classifier = nn.Sequential(
                nn.Linear(32 * 8, 128),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(128, num_classes)
            )
        else:
            # 特征维度适中时使用标准模型
            self.features = nn.Sequential(
                nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, padding=2),
                nn.BatchNorm1d(32),
                nn.ReLU(inplace=True),
                nn.MaxPool1d(kernel_size=2),

                nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
                nn.BatchNorm1d(64),
                nn.ReLU(inplace=True),
                nn.MaxPool1d(kernel_size=2),

                nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
                nn.BatchNorm1d(128),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool1d(16)
            )
            self.classifier = nn.Sequential(
                nn.Linear(128 * 16, 256),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(256, num_classes)
            )

    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x


# ------------------ 模型训练与评估函数 ------------------
def train_model(model, train_loader, val_loader, criterion, optimizer,
                num_epochs=100, patience=15):
    """训练模型并实现早停机制"""
    model.to(device)
    best_val_loss = float('inf')
    best_model_weights = None
    early_stop_counter = 0

    # 记录训练历史
    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': []
    }

    start_time = time.time()
    print("\n开始模型训练...")

    for epoch in range(num_epochs):
        # 训练阶段
        model.train()
        train_total = 0
        train_correct = 0
        train_running_loss = 0.0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # 清零梯度
            optimizer.zero_grad()

            # 前向传播
            outputs = model(inputs)
            loss = criterion(outputs, labels)

            # 反向传播和优化
            loss.backward()
            optimizer.step()

            # 统计训练数据
            train_running_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs.data, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()

        # 计算训练集指标
        train_epoch_loss = train_running_loss / train_total
        train_epoch_acc = train_correct / train_total
        history['train_loss'].append(train_epoch_loss)
        history['train_acc'].append(train_epoch_acc)

        # 验证阶段
        model.eval()
        val_total = 0
        val_correct = 0
        val_running_loss = 0.0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                val_running_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()

        # 计算验证集指标
        val_epoch_loss = val_running_loss / val_total
        val_epoch_acc = val_correct / val_total
        history['val_loss'].append(val_epoch_loss)
        history['val_acc'].append(val_epoch_acc)

        # 打印训练进度
        print(f"Epoch {epoch + 1}/{num_epochs}")
        print(f"训练: 损失={train_epoch_loss:.4f}, 准确率={train_epoch_acc:.4f}")
        print(f"验证: 损失={val_epoch_loss:.4f}, 准确率={val_epoch_acc:.4f}")
        print("-" * 60)

        # 早停检查
        if val_epoch_loss < best_val_loss:
            best_val_loss = val_epoch_loss
            best_model_weights = model.state_dict()
            early_stop_counter = 0
        else:
            early_stop_counter += 1
            if early_stop_counter >= patience:
                print(f"早停触发于第 {epoch + 1} 轮")
                break

    # 加载最佳模型权重
    model.load_state_dict(best_model_weights)
    training_time = time.time() - start_time
    print(f"训练完成，总耗时: {training_time:.2f}秒")

    return model, history


def evaluate_and_visualize(model, test_loader, class_names):
    """评估模型并可视化结果"""
    model.eval()
    y_true = []
    y_pred = []

    # 获取预测结果
    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)

            y_true.extend(labels.numpy())
            y_pred.extend(predicted.cpu().numpy())

    # 计算总体准确率
    accuracy = accuracy_score(y_true, y_pred)
    print(f"\n测试集准确率: {accuracy:.4f}")

    # 打印分类报告
    print("\n分类报告:")
    print(classification_report(
        y_true, y_pred,
        target_names=class_names,
        digits=4
    ))

    # 绘制混淆矩阵
    plt.figure(figsize=(10, 8))
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(
        cm,
        annot=True,
        fmt='d',
        cmap='Blues',
        xticklabels=class_names,
        yticklabels=class_names
    )
    plt.title(f'混淆矩阵 (准确率: {accuracy:.2%})')
    plt.xlabel('预测类别')
    plt.ylabel('真实类别')
    plt.tight_layout()
    plt.savefig('confusion_matrix.png', dpi=300)
    plt.close()

    # 绘制雷达图（多类别时）
    if len(class_names) > 1:
        categories = ['Precision', 'Recall', 'F1-score']
        plt.figure(figsize=(10, 10))
        ax = plt.subplot(111, polar=True)

        for i, cls in enumerate(class_names):
            try:
                stats = [
                    precision_score(y_true, y_pred, average=None)[i],
                    recall_score(y_true, y_pred, average=None)[i],
                    f1_score(y_true, y_pred, average=None)[i]
                ]
            except:
                stats = [0.0, 0.0, 0.0]

            # 标准化
            stats = (stats - np.min(stats)) / (np.max(stats) - np.min(stats) + 1e-8)
            stats = np.concatenate((stats, [stats[0]]))

            angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
            angles += angles[:1]

            ax.plot(angles, stats, linewidth=2, label=cls)
            ax.fill(angles, stats, alpha=0.1)

        ax.set_theta_offset(np.pi / 2)
        ax.set_theta_direction(-1)
        ax.set_thetagrids(np.degrees(angles[:-1]), categories)
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
        plt.title('各类别性能雷达图')
        plt.savefig('performance_radar.png', dpi=300, bbox_inches='tight')
        plt.close()

    return accuracy


def plot_training_history(history):
    """绘制训练过程中的损失和准确率曲线"""
    plt.figure(figsize=(12, 5))

    # 损失曲线
    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='训练损失')
    plt.plot(history['val_loss'], label='验证损失')
    plt.title('损失曲线')
    plt.xlabel('Epoch')
    plt.ylabel('损失')
    plt.legend()

    # 准确率曲线
    plt.subplot(1, 2, 2)
    plt.plot(history['train_acc'], label='训练准确率')
    plt.plot(history['val_acc'], label='验证准确率')
    plt.title('准确率曲线')
    plt.xlabel('Epoch')
    plt.ylabel('准确率')
    plt.legend()
loss
    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=300)
    plt.close()


# ------------------ 主函数 ------------------
def main(data_path=r"I:\杜恒旭·616\616文档备份\课题\揽绳\采集\PythonProject2\03.csv", window_size=20, overlap=0.5):
    """主函数：完整的分类流程，带滑动窗口处理"""
    # 创建保存目录
    os.makedirs('models', exist_ok=True)

    # 1. 读取数据
    print(f"读取数据文件: {data_path}")
    data = pd.read_csv(data_path)

    # 2. 解析类别和样本（第一行是标签，每列是该类别的样本）
    class_names = data.columns.tolist()
    num_classes = len(class_names)
    print(f"识别到 {num_classes} 个类别: {class_names}")

    # 提取样本和标签
    X = []  # 特征
    y = []  # 标签（类别索引）

    for class_idx, class_name in enumerate(class_names):
        # 获取该类别下的所有非空样本
        class_samples = data[class_name].dropna().values
        if len(class_samples) == 0:
            print(f"警告: 类别 {class_name} 没有有效样本，已跳过")
            continue

        # 使用滑动窗口分割长序列
        if len(class_samples) > window_size:
            windowed_samples = sliding_window_transform(
                class_samples, window_size, overlap
            )
            X.extend(windowed_samples)
            y.extend([class_idx] * len(windowed_samples))
            print(f"类别 {class_name}: {len(class_samples)} 个数据点 → {len(windowed_samples)} 个窗口样本")
        else:
            # 如果序列长度小于窗口大小，直接作为单个样本（补零处理）
            padded_sample = np.pad(class_samples, (0, max(0, window_size - len(class_samples))),
                                   mode='constant')
            X.append(padded_sample)
            y.append(class_idx)
            print(f"类别 {class_name}: 序列过短({len(class_samples)})，补零后作为1个样本")

    # 转换为numpy数组
    X = np.array(X)
    y = np.array(y)
    print(f"总样本数: {X.shape[0]}, 每个样本特征维度: {X.shape[1]} (窗口大小)")

    # 3. 数据预处理
    print("\n应用FFT变换...")
    X_fft = apply_fft(X)
    print(f"FFT处理后特征维度: {X_fft.shape[1]}")

    # 标准化
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_fft)

    # 4. 划分数据集
    X_train_val, X_test, y_train_val, y_test = train_test_split(
        X_scaled, y, test_size=0.2, stratify=y, random_state=SEED
    )

    X_train, X_val, y_train, y_val = train_test_split(
        X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=SEED
    )  # 0.25 * 0.8 = 0.2

    print(f"数据集划分: 训练集={X_train.shape[0]}, 验证集={X_val.shape[0]}, 测试集={X_test.shape[0]}")

    # 5. 转换为PyTorch张量并添加通道维度
    X_train_tensor = torch.FloatTensor(X_train).unsqueeze(1)  # 形状: [N, 1, features]
    y_train_tensor = torch.LongTensor(y_train)
    X_val_tensor = torch.FloatTensor(X_val).unsqueeze(1)
    y_val_tensor = torch.LongTensor(y_val)
    X_test_tensor = torch.FloatTensor(X_test).unsqueeze(1)
    y_test_tensor = torch.LongTensor(y_test)

    # 创建数据加载器
    batch_size = 32
    train_loader = DataLoader(
        TensorDataset(X_train_tensor, y_train_tensor),
        batch_size=batch_size,
        shuffle=True
    )
    val_loader = DataLoader(
        TensorDataset(X_val_tensor, y_val_tensor),
        batch_size=batch_size,
        shuffle=False
    )
    test_loader = DataLoader(
        TensorDataset(X_test_tensor, y_test_tensor),
        batch_size=batch_size,
        shuffle=False
    )

    # 6. 初始化模型、损失函数和优化器
    input_dim = X_fft.shape[1]
    print(f"初始化模型，输入特征维度: {input_dim}")
    model = FFT_CNN1D(input_dim=input_dim, num_classes=num_classes)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)

    # 7. 训练模型
    trained_model, history = train_model(
        model, train_loader, val_loader,
        criterion, optimizer,
        num_epochs=100,
        patience=15
    )

    # 8. 绘制训练历史曲线
    plot_training_history(history)

    # 9. 评估模型
    test_accuracy = evaluate_and_visualize(trained_model, test_loader, class_names)

    # 10. 保存模型和预处理工具
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_save_path = f"models/cnn_model_{timestamp}.pth"
    torch.save(trained_model.state_dict(), model_save_path)
    joblib.dump(scaler, "models/scaler.pkl")

    # 保存类别信息和窗口参数
    with open("models/class_info.txt", "w") as f:
        f.write(f"类别数量: {num_classes}\n")
        f.write(f"类别名称: {class_names}\n")
        f.write(f"窗口大小: {window_size}\n")
        f.write(f"重叠率: {overlap}\n")
        f.write(f"输入特征维度: {input_dim}\n")
        f.write(f"测试集准确率: {test_accuracy:.4f}\n")
        f.write(f"保存时间: {timestamp}\n")

    print(f"\n模型已保存至: {model_save_path}")
    print(f"标准化器已保存至: models/scaler.pkl")
    print("可视化结果已保存为PNG文件")


if __name__ == "__main__":
    # 滑动窗口参数设置（核心修改）
    DATA_FILE = r"I:\杜恒旭·616\616文档备份\课题\揽绳\采集\PythonProject2\03.csv"  # 数据文件路径
    WINDOW_SIZE = 70  # 滑动窗口大小，建议从20开始，可尝试10-50
    OVERLAP_RATE = 0.8  # 滑动窗口重叠率，0.5表示50%重叠

    # 运行主程序
    main(data_path=DATA_FILE, window_size=WINDOW_SIZE, overlap=OVERLAP_RATE)
