import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import TensorDataset, DataLoader
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import (accuracy_score, precision_score,
                             recall_score, f1_score,
                             confusion_matrix, classification_report)
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
import joblib
import os
import time
from datetime import datetime
import warnings


warnings.filterwarnings("ignore")


def set_chinese_font():
    # 常见的中文字体列表
    font_list = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Heiti TC', 'WenQuanYi Micro Hei']
    detected_font = None

    for font in font_list:
        try:
            # 尝试加载字体
            matplotlib.font_manager.findfont(font, fallback_to_default=False)
            plt.rcParams['font.sans-serif'] = [font]
            plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题
            detected_font = font
            print(f": {font}")
            break
        except:
            continue

    if detected_font is None:
        print("警告: 未检测到常见字体，图片中的中文可能显示为方框。")


set_chinese_font()
# ------------------------------------------------------------------

# 设置随机种子确保可复现性
SEED = 42
torch.manual_seed(SEED)
np.random.seed(SEED)

# 设备配置
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"使用计算设备: {device}")


# ------------------ 数据预处理函数 ------------------
def apply_fft(features):
    """对输入特征应用FFT变换，保留有效频率成分"""
    fft_results = np.abs(np.fft.fft(features))
    num_features = features.shape[1]
    valid_fft = fft_results[:, :num_features // 2 + 1]  # 利用FFT对称性
    return valid_fft


def sliding_window_transform(signal, window_size=70, overlap=0.8):
    """将长序列信号转换为多个滑动窗口样本"""
    stride = int(window_size * (1 - overlap))
    stride = max(1, stride)
    windows = []
    num_windows = (len(signal) - window_size) // stride + 1

    for i in range(num_windows):
        start = i * stride
        end = start + window_size
        windows.append(signal[start:end])

    return np.array(windows)


# ------------------ 1D CNN模型定义 ------------------
class FFT_CNN1D(nn.Module):
    def __init__(self, input_dim, num_classes, dropout_rate=0.5):
        super(FFT_CNN1D, self).__init__()

        if input_dim <= 2:
            self.features = nn.Sequential(
                nn.Conv1d(in_channels=1, out_channels=16, kernel_size=1, padding=0),
                nn.BatchNorm1d(16),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool1d(4)
            )
            self.classifier = nn.Sequential(
                nn.Linear(16 * 4, 64),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(64, num_classes)
            )
        elif input_dim <= 10:
            self.features = nn.Sequential(
                nn.Conv1d(in_channels=1, out_channels=16, kernel_size=3, padding=1),
                nn.BatchNorm1d(16),
                nn.ReLU(inplace=True),
                nn.MaxPool1d(kernel_size=2, stride=1),
                nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1),
                nn.BatchNorm1d(32),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool1d(8)
            )
            self.classifier = nn.Sequential(
                nn.Linear(32 * 8, 128),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(128, num_classes)
            )
        else:
            self.features = nn.Sequential(
                nn.Conv1d(in_channels=1, out_channels=32, kernel_size=5, padding=2),
                nn.BatchNorm1d(32),
                nn.ReLU(inplace=True),
                nn.MaxPool1d(kernel_size=2),

                nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1),
                nn.BatchNorm1d(64),
                nn.ReLU(inplace=True),
                nn.MaxPool1d(kernel_size=2),

                nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1),
                nn.BatchNorm1d(128),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool1d(16)
            )
            self.classifier = nn.Sequential(
                nn.Linear(128 * 16, 256),
                nn.ReLU(inplace=True),
                nn.Dropout(dropout_rate),
                nn.Linear(256, num_classes)
            )

    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x


# ------------------ 模型训练与评估函数 ------------------
def train_model(model, train_loader, val_loader, criterion, optimizer,
                num_epochs=100, patience=15):
    """训练模型并实现早停机制"""
    model.to(device)
    best_val_loss = float('inf')
    best_model_weights = None
    early_stop_counter = 0

    history = {
        'train_loss': [], 'train_acc': [],
        'val_loss': [], 'val_acc': []
    }

    start_time = time.time()
    print("\n开始模型训练 (无噪声注入)...")

    for epoch in range(num_epochs):
        # 训练阶段
        model.train()
        train_total = 0
        train_correct = 0
        train_running_loss = 0.0

        for inputs, labels in train_loader:
            inputs, labels = inputs.to(device), labels.to(device)

            # === [已修改] 这里移除了噪声注入代码，恢复纯净训练 ===

            # 清零梯度
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            train_running_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs.data, 1)
            train_total += labels.size(0)
            train_correct += (predicted == labels).sum().item()

        train_epoch_loss = train_running_loss / train_total
        train_epoch_acc = train_correct / train_total
        history['train_loss'].append(train_epoch_loss)
        history['train_acc'].append(train_epoch_acc)

        # 验证阶段
        model.eval()
        val_total = 0
        val_correct = 0
        val_running_loss = 0.0

        with torch.no_grad():
            for inputs, labels in val_loader:
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                val_running_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs.data, 1)
                val_total += labels.size(0)
                val_correct += (predicted == labels).sum().item()

        val_epoch_loss = val_running_loss / val_total
        val_epoch_acc = val_correct / val_total
        history['val_loss'].append(val_epoch_loss)
        history['val_acc'].append(val_epoch_acc)

        print(f"Epoch {epoch + 1}/{num_epochs}")
        print(f"训练: 损失={train_epoch_loss:.4f}, 准确率={train_epoch_acc:.4f}")
        print(f"验证: 损失={val_epoch_loss:.4f}, 准确率={val_epoch_acc:.4f}")
        print("-" * 60)

        if val_epoch_loss < best_val_loss:
            best_val_loss = val_epoch_loss
            best_model_weights = model.state_dict()
            early_stop_counter = 0
        else:
            early_stop_counter += 1
            if early_stop_counter >= patience:
                print(f"早停触发于第 {epoch + 1} 轮")
                break

    model.load_state_dict(best_model_weights)
    training_time = time.time() - start_time
    print(f"训练完成，总耗时: {training_time:.2f}秒")

    return model, history


def evaluate_and_visualize(model, test_loader, class_names):
    """评估模型并可视化结果"""
    model.eval()
    y_true = []
    y_pred = []

    with torch.no_grad():
        for inputs, labels in test_loader:
            inputs = inputs.to(device)
            outputs = model(inputs)
            _, predicted = torch.max(outputs.data, 1)

            y_true.extend(labels.numpy())
            y_pred.extend(predicted.cpu().numpy())

    accuracy = accuracy_score(y_true, y_pred)
    print(f"\n测试集准确率: {accuracy:.4f}")

    print("\n分类报告:")
    print(classification_report(y_true, y_pred, target_names=class_names, digits=4))

    # 混淆矩阵
    plt.figure(figsize=(10, 8))
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names)
    plt.title(f'混淆矩阵 (准确率: {accuracy:.2%})')
    plt.xlabel('预测类别')
    plt.ylabel('真实类别')
    plt.tight_layout()
    plt.savefig('confusion_matrix.png', dpi=300)
    plt.close()

    # 雷达图
    if len(class_names) > 1:
        categories = ['Precision', 'Recall', 'F1-score']
        plt.figure(figsize=(10, 10))
        ax = plt.subplot(111, polar=True)

        for i, cls in enumerate(class_names):
            try:
                stats = [
                    precision_score(y_true, y_pred, average=None)[i],
                    recall_score(y_true, y_pred, average=None)[i],
                    f1_score(y_true, y_pred, average=None)[i]
                ]
            except:
                stats = [0.0, 0.0, 0.0]

            stats = (stats - np.min(stats)) / (np.max(stats) - np.min(stats) + 1e-8)
            stats = np.concatenate((stats, [stats[0]]))
            angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
            angles += angles[:1]

            ax.plot(angles, stats, linewidth=2, label=cls)
            ax.fill(angles, stats, alpha=0.1)

        ax.set_theta_offset(np.pi / 2)
        ax.set_theta_direction(-1)
        ax.set_thetagrids(np.degrees(angles[:-1]), categories)
        ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
        plt.title('各类别性能雷达图')
        plt.savefig('performance_radar.png', dpi=300, bbox_inches='tight')
        plt.close()

    return accuracy


def evaluate_robustness_with_noise(model, test_loader, class_names, noise_levels=[0, 0.05, 0.1, 0.2, 0.3]):
    """The robustness of the model is evaluated by injecting noise of different intensities into the test set"""
    print("\n" + "=" * 20 + " 开始噪声鲁棒性测试 (泛化验证) " + "=" * 20)
    model.eval()

    accuracies = []

    for noise_level in noise_levels:
        correct = 0
        total = 0

        with torch.no_grad():
            for inputs, labels in test_loader:
                inputs, labels = inputs.to(device), labels.to(device)

                # 注入噪声
                noise = torch.randn_like(inputs) * noise_level
                noisy_inputs = inputs + noise

                outputs = model(noisy_inputs)
                _, predicted = torch.max(outputs.data, 1)

                total += labels.size(0)
                correct += (predicted == labels).sum().item()

        acc = correct / total
        accuracies.append(acc)
        print(f"噪声强度: {noise_level:.2f} -> 测试准确率: {acc:.4f}")

    # 绘制鲁棒性曲线
    plt.figure(figsize=(10, 6))
    plt.plot(noise_levels, accuracies, marker='o', linewidth=2, linestyle='-', color='#d62728')
    plt.title('Anti-noise capability (Robustness Test)')
    plt.xlabel('Injection noise intensity (standard deviation multiple)')
    plt.ylabel('Model accuracy')
    plt.grid(True, linestyle='--', alpha=0.7)

    for i, txt in enumerate(accuracies):
        plt.annotate(f"{txt:.2%}", (noise_levels[i], accuracies[i]),
                     xytext=(0, 10), textcoords='offset points', ha='center', fontsize=9)

    plt.ylim(0, 1.1)
    plt.tight_layout()
    plt.savefig('robustness_curve.png', dpi=300)
    print("鲁棒性曲线已保存为 'robustness_curve.png'")
    print("=" * 60)

    return accuracies


def plot_training_history(history):
    """绘制训练过程中的损失和准确率曲线"""
    plt.figure(figsize=(12, 5))

    plt.subplot(1, 2, 1)
    plt.plot(history['train_loss'], label='train_loss')
    plt.plot(history['val_loss'], label='val_loss')
    plt.title('Loss curve')
    plt.xlabel('Epoch')
    plt.ylabel('loss')
    plt.legend()

    plt.subplot(1, 2, 2)
    plt.plot(history['train_acc'], label='train_acc')
    plt.plot(history['val_acc'], label='val_acc')
    plt.title('Accuracy curve')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.tight_layout()
    plt.savefig('training_curves.png', dpi=300)
    plt.close()


# ------------------ 主函数 ------------------
def main(data_path, window_size=20, overlap=0.5):
    """主函数：完整的分类流程，带滑动窗口处理"""
    os.makedirs('models', exist_ok=True)

    # 1. 读取数据
    print(f"读取数据文件: {data_path}")
    data = pd.read_csv(data_path)

    # 2. 解析类别和样本
    class_names = data.columns.tolist()
    num_classes = len(class_names)
    print(f"识别到 {num_classes} 个类别: {class_names}")

    X = []
    y = []

    for class_idx, class_name in enumerate(class_names):
        class_samples = data[class_name].dropna().values
        if len(class_samples) == 0:
            print(f"警告: 类别 {class_name} 没有有效样本，已跳过")
            continue

        if len(class_samples) > window_size:
            windowed_samples = sliding_window_transform(
                class_samples, window_size, overlap
            )
            X.extend(windowed_samples)
            y.extend([class_idx] * len(windowed_samples))
            print(f"类别 {class_name}: {len(class_samples)} 个数据点 → {len(windowed_samples)} 个窗口样本")
        else:
            padded_sample = np.pad(class_samples, (0, max(0, window_size - len(class_samples))),
                                   mode='constant')
            X.append(padded_sample)
            y.append(class_idx)
            print(f"类别 {class_name}: 序列过短，补零处理")

    X = np.array(X)
    y = np.array(y)
    print(f"总样本数: {X.shape[0]}, 每个样本特征维度: {X.shape[1]}")

    # 3. 数据预处理 (FFT)
    print("\n应用FFT变换...")
    X_fft = apply_fft(X)
    print(f"FFT处理后特征维度: {X_fft.shape[1]}")

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_fft)

    # 4. 划分数据集
    X_train_val, X_test, y_train_val, y_test = train_test_split(
        X_scaled, y, test_size=0.2, stratify=y, random_state=SEED
    )

    X_train, X_val, y_train, y_val = train_test_split(
        X_train_val, y_train_val, test_size=0.25, stratify=y_train_val, random_state=SEED
    )

    print(f"数据集划分: 训练集={X_train.shape[0]}, 验证集={X_val.shape[0]}, 测试集={X_test.shape[0]}")

    X_train_tensor = torch.FloatTensor(X_train).unsqueeze(1)
    y_train_tensor = torch.LongTensor(y_train)
    X_val_tensor = torch.FloatTensor(X_val).unsqueeze(1)
    y_val_tensor = torch.LongTensor(y_val)
    X_test_tensor = torch.FloatTensor(X_test).unsqueeze(1)
    y_test_tensor = torch.LongTensor(y_test)

    batch_size = 32
    train_loader = DataLoader(TensorDataset(X_train_tensor, y_train_tensor), batch_size=batch_size, shuffle=True)
    val_loader = DataLoader(TensorDataset(X_val_tensor, y_val_tensor), batch_size=batch_size, shuffle=False)
    test_loader = DataLoader(TensorDataset(X_test_tensor, y_test_tensor), batch_size=batch_size, shuffle=False)

    # 6. 初始化模型
    input_dim = X_fft.shape[1]
    model = FFT_CNN1D(input_dim=input_dim, num_classes=num_classes)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-5)

    # 7. 训练模型 (恢复正常的 epoch 数量，不需要那么多轮了)
    trained_model, history = train_model(
        model, train_loader, val_loader,
        criterion, optimizer,
        num_epochs=100,
        patience=15
    )

    # 8. 绘制训练历史
    plot_training_history(history)

    # 9. 常规评估
    test_accuracy = evaluate_and_visualize(trained_model, test_loader, class_names)

    # 10. 噪声鲁棒性测试 (保留测试，以观察不加噪训练的效果)
    noise_levels_to_test = [0, 0.02, 0.04, 0.06, 0.08, 0.1]
    evaluate_robustness_with_noise(trained_model, test_loader, class_names, noise_levels_to_test)

    # 11. 保存模型
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    model_save_path = f"models/cnn_model_{timestamp}.pth"
    torch.save(trained_model.state_dict(), model_save_path)
    joblib.dump(scaler, "models/scaler.pkl")

    with open("models/class_info.txt", "w") as f:
        f.write(f"类别数量: {num_classes}\n")
        f.write(f"类别名称: {class_names}\n")
        f.write(f"窗口大小: {window_size}\n")
        f.write(f"重叠率: {overlap}\n")
        f.write(f"测试集准确率: {test_accuracy:.4f}\n")
        f.write(f"保存时间: {timestamp}\n")

    print(f"\n模型已保存至: {model_save_path}")
    print(f"可视化结果已保存为PNG文件")


if __name__ == "__main__":
    # 滑动窗口参数设置
    DATA_FILE = r"xxx.csv"
    WINDOW_SIZE = 70
    OVERLAP_RATE = 0.8

    main(data_path=DATA_FILE, window_size=WINDOW_SIZE, overlap=OVERLAP_RATE)
